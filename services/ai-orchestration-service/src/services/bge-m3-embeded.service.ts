import { pipeline, FeatureExtractionPipeline } from '@xenova/transformers';

// Types
interface EmbeddingOptions {
    normalize?: boolean;
    pooling?: 'cls' | 'mean';
}

interface BatchEmbeddingOptions extends EmbeddingOptions {
    batchSize?: number;
}

interface SimilarityResult {
    text: string;
    similarity: number;
    index: number;
}

interface ModelStatus {
    loaded: boolean;
    loading: boolean;
    modelName: string;
    embeddingSize: number;
}

// Global model instance (singleton)
let embeddingModel: FeatureExtractionPipeline | null = null;
let isLoading: boolean = false;

/**
 * Kh·ªüi t·∫°o m√¥ h√¨nh BGE-M3 (ch·ªâ g·ªçi m·ªôt l·∫ßn khi kh·ªüi ƒë·ªông).
 */
async function initEmbeddingModel(): Promise<FeatureExtractionPipeline> {
    if (embeddingModel) return embeddingModel;

    if (isLoading) {
        // Ch·ªù qu√° tr√¨nh t·∫£i ƒëang di·ªÖn ra
        while (isLoading) {
            await sleep(100);
        }
        return embeddingModel!;
    }

    try {
        isLoading = true;
        console.log('üîÑ Loading BGE-M3 model... (this may take 1-2 minutes)');

        embeddingModel = await pipeline(
            'feature-extraction',
            'Xenova/bge-m3',
            {
                quantized: true, // Gi·∫£m s·ª≠ d·ª•ng b·ªô nh·ªõ
                progress_callback: (progress: any) => {
                    if (progress.status === 'downloading') {
                        console.log(`üì• Downloading: ${Math.round(progress.progress || 0)}%`);
                    }
                }
            }
        );

        console.log('‚úÖ BGE-M3 model loaded successfully');
        return embeddingModel;

    } catch (error) {
        console.error('‚ùå Failed to load BGE-M3 model:', error);
        throw error;
    } finally {
        isLoading = false;
    }
}

/**
 * T·∫°o m·ªôt embedding duy nh·∫•t.
 */
async function generateEmbedding(
    text: string,
    options: EmbeddingOptions = {}
): Promise<number[]> {
    if (!embeddingModel) {
        await initEmbeddingModel();
    }

    try {
        const { normalize = true, pooling = 'cls' } = options;

        const output = await embeddingModel!(text, {
            pooling,
            normalize
        });

        // Chuy·ªÉn ƒë·ªïi sang m·∫£ng th√¥ng th∆∞·ªùng
        return Array.from(output.data as Float32Array);

    } catch (error) {
        console.error('‚ùå Embedding generation failed:', error);
        throw error;
    }
}

/**
 * T·∫°o c√°c embedding theo l√¥ (hi·ªáu qu·∫£ h∆°n).
 */
async function generateBatchEmbeddings(
    texts: string[],
    options: BatchEmbeddingOptions = {}
): Promise<number[][]> {
    if (!embeddingModel) {
        await initEmbeddingModel();
    }

    if (!Array.isArray(texts) || texts.length === 0) {
        throw new Error('texts must be a non-empty array');
    }

    try {
        const { normalize = true, pooling = 'cls', batchSize = 8 } = options;
        const allEmbeddings: number[][] = [];

        // X·ª≠ l√Ω theo t·ª´ng kh·ªëi ƒë·ªÉ tr√°nh c√°c v·∫•n ƒë·ªÅ v·ªÅ b·ªô nh·ªõ
        for (let i = 0; i < texts.length; i += batchSize) {
            const batch = texts.slice(i, i + batchSize);
            console.log(`üîÑ Processing batch ${Math.floor(i/batchSize) + 1}/${Math.ceil(texts.length/batchSize)}`);

            const batchOutput = await embeddingModel!(batch, {
                pooling,
                normalize
            });

            const outputData = batchOutput.data as Float32Array;

            // X·ª≠ l√Ω ƒë·∫ßu ra ƒë∆°n l·∫ª so v·ªõi nhi·ªÅu ƒë·∫ßu ra
            if (batch.length === 1) {
                allEmbeddings.push(Array.from(outputData));
            } else {
                // Nhi·ªÅu embedding ƒë∆∞·ª£c tr·∫£ v·ªÅ d∆∞·ªõi d·∫°ng c·∫•u tr√∫c l·ªìng nhau
                for (let j = 0; j < batch.length; j++) {
                    const start = j * 1024; // K√≠ch th∆∞·ªõc embedding c·ªßa BGE-M3
                    const end = start + 1024;
                    allEmbeddings.push(Array.from(outputData.slice(start, end)));
                }
            }
        }

        return allEmbeddings;

    } catch (error) {
        console.error('‚ùå Batch embedding generation failed:', error);
        throw error;
    }
}

/**
 * T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng cosine gi·ªØa hai embedding.
 */
function cosineSimilarity(embedding1: number[], embedding2: number[]): number {
    if (embedding1.length !== embedding2.length) {
        throw new Error('Embeddings must have same dimensions');
    }

    let dotProduct = 0;
    let norm1 = 0;
    let norm2 = 0;

    for (let i = 0; i < embedding1.length; i++) {
        dotProduct += embedding1[i] * embedding2[i];
        norm1 += embedding1[i] * embedding1[i];
        norm2 += embedding2[i] * embedding2[i];
    }

    return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
}

/**
 * T√¨m c√°c vƒÉn b·∫£n t∆∞∆°ng t·ª± nh·∫•t t·ª´ m·ªôt t·∫≠p h·ª£p.
 */
async function findSimilar(
    query: string,
    corpus: string[],
    topK: number = 5
): Promise<SimilarityResult[]> {
    console.log(`üîç Finding ${topK} most similar texts for query`);

    // T·∫°o c√°c embedding
    const queryEmbedding = await generateEmbedding(query);
    const corpusEmbeddings = await generateBatchEmbeddings(corpus);

    // T√≠nh to√°n ƒë·ªô t∆∞∆°ng ƒë·ªìng
    const similarities: SimilarityResult[] = corpusEmbeddings.map((embedding, index) => ({
        text: corpus[index],
        similarity: cosineSimilarity(queryEmbedding, embedding),
        index
    }));

    // S·∫Øp x·∫øp theo ƒë·ªô t∆∞∆°ng ƒë·ªìng v√† tr·∫£ v·ªÅ top K
    return similarities
        .sort((a, b) => b.similarity - a.similarity)
        .slice(0, topK);
}

/**
 * Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n PlantUML ƒë·ªÉ c√≥ c√°c embedding t·ªët h∆°n.
 */
function preprocessPlantUML(plantUMLText: string): string {
    // X√≥a c√°c th·∫ª @startuml/@enduml
    let processed = plantUMLText
        .replace(/@startuml[\s\S]*?\n/g, '')
        .replace(/@enduml/g, '')
        .trim();

    // Tr√≠ch xu·∫•t v√† chu·∫©n h√≥a c√°c ph·∫ßn t·ª≠ PlantUML
    const elements: string[] = [];

    // Tr√≠ch xu·∫•t c√°c class, participant, component, v.v.
    const patterns: Record<string, RegExp> = {
        'class definition': /class\s+(\w+)/g,
        'participant': /participant\s+(\w+)/g,
        'component': /component\s+(\w+)/g,
        'relationship': /(\w+)\s*(-->|->|\*-->|\*->|<\|--)\s*(\w+)/g
    };

    for (const [type, pattern] of Object.entries(patterns)) {
        const matches = processed.match(pattern) || [];
        matches.forEach(match => {
            elements.push(`${type}: ${match}`);
        });
    }

    return elements.length > 0 ? elements.join(' ') : processed;
}

// Helper functions
function sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
}

function getModelStatus(): ModelStatus {
    return {
        loaded: embeddingModel !== null,
        loading: isLoading,
        modelName: 'BAAI/bge-m3',
        embeddingSize: 1024
    };
}

// Export functions
export {
    initEmbeddingModel,
    generateEmbedding,
    generateBatchEmbeddings,
    cosineSimilarity,
    findSimilar,
    preprocessPlantUML,
    getModelStatus,
    // Types
    type EmbeddingOptions,
    type BatchEmbeddingOptions,
    type SimilarityResult,
    type ModelStatus
};